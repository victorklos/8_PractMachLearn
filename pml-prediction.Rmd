---
title: "PML Prediction"
author: "Victor Klos"
date: "13-03-2015"
output: html_document
---

TODO introduction 


## Loading and cleaning the data

The data is already split into a training and testing set. The format is `csv` which is readily handled by R (even though the extraneous quotes require a bit of a detour). Running a `summary` on the training set reveals that many columns contain the phrase `#DIV/0!`, so the data suffers from an export problem. Also, the column names are not 'tidy' as they contain underscores.

Knowing this, loading and tidying becomes:

```{r}
nas <- c("", "\"\"", "NA", "#DIV/0!")
training <- read.csv("pml-training.csv", colClasses="character", na.strings=nas)
testing <- read.csv("pml-testing.csv", colClasses="character", na.strings=nas)
colnames(training) <- colnames(testing) <- tolower(gsub("_", ".", colnames(training)))

classes <- c("integer", rep("factor", 5), rep("numeric", 153), "factor")
for (i in 1:ncol(training)) {
  training[,i] <- do.call(paste("as", classes[i], sep="."), list(training[,i]))
  testing[,i] <- do.call(paste("as", classes[i], sep="."), list(testing[,i]))
}
testing <- testing[-ncol(testing)]
```

The training data set contains `r dim(training)[2]` columns. The testing data set has one less; it is the 'classe' column that needs to be predicted. The training set contains `r dim(training)[1]` rows and the testing set has `r dim(testing)[1]` rows.


## Exploratory analysis

From looking at the summary it was obvious that many columns in the training dataset suffer from missing values. Let's examine the extent of this potential problem:

```{r}
nas.per.col <- apply(training, 2, FUN=function(col) sum(is.na(col)))
table(nas.per.col)
```

This overview tells us that _(i)_ NA's are abundant and _(ii)_ there is no fixing them as there exist no columns with only a few missing values. Hence, all columns with NA's will be removed from the dataset.

Additionally, the rows with the index, user name, time stamps and window information will not aid in building a good predictor so these are removed too:

```{r}
cols.to.remove <- c(1:7, which(nas.per.col > 0))
training <- training[-cols.to.remove]
testing <- testing[-cols.to.remove]
```

Next, we can check if the remaining data isn't near zero or without variance:

```{r, message=F}
library(caret)
nz <- nearZeroVar(training, saveMetrics=T)
sum(nz$zeroVar) + sum(nz$nzv)
```

The outcome of zero indicates that all data may have relevance for the predictor.


## Building predictors

The goal of the assignment is to build a predictor for the `classe` variable:

```{r, echo=F}
summary(training$classe)
```

```{r, echo=F}
# Set up for parallel processing as per
# https://class.coursera.org/predmachlearn-012/forum/thread?thread_id=61
library(parallel); library(doParallel)
registerDoParallel(clust <- makeForkCluster(detectCores()-1))
```

It is well known that `random forests` (RF) give the best out-of-the-box results when it comes to building predictors. Their results however are not very human-interpretable. For this reason `rpart`, a recursive partitioning model, is also included. While looking for alternatives to RF a `neural network` was tried too but with little success ($$<<50%$$ accuracy).

```{r, message=F}
set.seed(42)

training <- training[sample(nrow(training), nrow(training)*.5),] # keep half samples
validation <- testing
testing <- 
eval <- training[sample(nrow(training), 400),]
training <- training[sample(nrow(training), 2000),]
fit.rf <- train(classe ~ ., data=training, method="rf")
fit.rp <- train(classe ~ ., data=training, method="rpart2")
fit.nn <- train(classe ~ ., data=training, method="nnet", maxit = 1000,
                tuneGrid = expand.grid(.decay = .025, .size = c(11,25)),
                trace = F, linout = T)
```

### Results of Random Forest

```{r}
cm <- confusionMatrix(predict(fit.rf, newdata=eval), eval$classe)
cm$table
cm$overall
```

### Results of Recursive Partitioning

```{r}
cm <- confusionMatrix(predict(fit.rp, newdata=eval), eval$classe)
cm$table
cm$overall
```

### Results of Neural Network

```{r}
cm <- confusionMatrix(predict(fit.nn, newdata=eval), eval$classe)
cm$table
cm$overall
```

## Appendix: Training data summary

## Next

```{r, echo=F}
summary(training)
```

